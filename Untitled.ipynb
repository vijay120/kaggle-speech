{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "yes_path = \"/Users/vijayrk/kaggle-speech/yes-small-mono/\"\n",
    "yes_files = [os.path.join(yes_path, f) for f in listdir(yes_path) if isfile(join(yes_path, f))]\n",
    "\n",
    "no_path = \"/Users/vijayrk/kaggle-speech/no-small-mono/\"\n",
    "no_files = [os.path.join(no_path, f) for f in listdir(no_path) if isfile(join(no_path, f))]\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for files in yes_files:\n",
    "    sample_rate, samples = wavfile.read(files)\n",
    "    frequencies, times, spectogram = signal.spectrogram(samples, sample_rate)\n",
    "    spectogram = spectogram[:, :71]\n",
    "    X.append(spectogram)\n",
    "    Y.append([1,0])\n",
    "    \n",
    "\n",
    "for files in no_files:\n",
    "    sample_rate, samples = wavfile.read(files)\n",
    "    frequencies, times, spectogram = signal.spectrogram(samples, sample_rate)\n",
    "    spectogram = spectogram[:, :71]\n",
    "    X.append(spectogram)\n",
    "    Y.append([0,1])\n",
    "    \n",
    "examples = np.asarray(X)\n",
    "labels = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 71)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate, samples = wavfile.read(\"/Users/vijayrk/kaggle-speech/no-small/9e075bf1_nohash_0.wav\")\n",
    "frequencies, times, spectogram = signal.spectrogram(samples, sample_rate)\n",
    "spectogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.008,  0.022,  0.036,  0.05 ,  0.064,  0.078,  0.092,  0.106,\n",
       "        0.12 ,  0.134,  0.148,  0.162,  0.176,  0.19 ,  0.204,  0.218,\n",
       "        0.232,  0.246,  0.26 ,  0.274,  0.288,  0.302,  0.316,  0.33 ,\n",
       "        0.344,  0.358,  0.372,  0.386,  0.4  ,  0.414,  0.428,  0.442,\n",
       "        0.456,  0.47 ,  0.484,  0.498,  0.512,  0.526,  0.54 ,  0.554,\n",
       "        0.568,  0.582,  0.596,  0.61 ,  0.624,  0.638,  0.652,  0.666,\n",
       "        0.68 ,  0.694,  0.708,  0.722,  0.736,  0.75 ,  0.764,  0.778,\n",
       "        0.792,  0.806,  0.82 ,  0.834,  0.848,  0.862,  0.876,  0.89 ,\n",
       "        0.904,  0.918,  0.932,  0.946,  0.96 ,  0.974,  0.988])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 129, 71)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [1,5,10]\n",
    "examples[indices].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dir, ques):\n",
    "\tlb = preprocessing.LabelBinarizer()\n",
    "\n",
    "\tfolders = [os.path.join(dir, f) for f in listdir(dir) \n",
    "\t\t\t\tif not isfile(join(dir, f))]\n",
    "\n",
    "\tque_dict = {}\n",
    "\tfor folder in folders:\n",
    "\t\tfor que in ques:\n",
    "\t\t\tif que in folder:\n",
    "\t\t\t\tque_dict[que] = folder\n",
    "\n",
    "\tlb.fit(list(que_dict.keys()))\n",
    "\n",
    "\tX = []\n",
    "\tY = []\n",
    "\n",
    "\tfor que in que_dict.keys():\n",
    "\t\tfolder = que_dict[que]\n",
    "\t\tfor file in [os.path.join(folder, f) for f in listdir(folder) if isfile(join(folder, f))]:\n",
    "\t\t\tsample_rate, samples = wavfile.read(files)\n",
    "\t\t\tfrequencies, times, spectogram = signal.spectrogram(samples, sample_rate)\n",
    "\t\t\tspectogram = spectogram[:, :71]\n",
    "\t\t\tX.append(spectogram)\n",
    "\t\t\tY.append(lb.transform([que])[0])\n",
    "\n",
    "\texamples = np.asarray(X)\n",
    "\tlabels = np.asarray(Y)\n",
    "\n",
    "\treturn examples, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples, labels = get_data(\"/Users/vijayrk/kaggle-speech\", [\"no-small\", \"yes-small\", \"no-small-mono\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 500\n",
    "batch_size = 5\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 2 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, examples.shape[1], examples.shape[2]])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(129), Dimension(71)])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
    "    # Reshape to match picture format [Height x Width x Channel]\n",
    "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "    x = tf.reshape(x, shape=[-1, 129, 71, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "# spectogram_reshape = tf.reshape(spectogram, [1, spectogram.shape[0], spectogram.shape[1], 1])\n",
    "# print(spectogram_reshape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([33*18*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "logits = conv_net(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 2, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 3, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 4, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 5, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 6, Minibatch Loss= 11179289600.0000, Training Accuracy= 0.400\n",
      "Step 7, Minibatch Loss= 658778624.0000, Training Accuracy= 0.600\n",
      "Step 8, Minibatch Loss= 30913155072.0000, Training Accuracy= 0.200\n",
      "Step 9, Minibatch Loss= 7293127680.0000, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 2807205376.0000, Training Accuracy= 0.000\n",
      "Step 11, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x = examples[(step-1)*batch_size : step*batch_size]\n",
    "        batch_y = labels[(step-1)*batch_size : step*batch_size]\n",
    "        \n",
    "        if len(batch_x) == 0:\n",
    "            break\n",
    "                \n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y,\n",
    "                                                                 keep_prob: 1.0})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_x, batch_y = mnist.train.next_batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/vijayrk/kaggle-speech/.ipynb_checkpoints', '/Users/vijayrk/kaggle-speech/no-small', '/Users/vijayrk/kaggle-speech/no-small-mono', '/Users/vijayrk/kaggle-speech/tensorflow', '/Users/vijayrk/kaggle-speech/yes-small', '/Users/vijayrk/kaggle-speech/yes-small-mono']\n"
     ]
    }
   ],
   "source": [
    "yes_path = \"/Users/vijayrk/kaggle-speech\"\n",
    "yes_files = [os.path.join(yes_path, f) for f in listdir(yes_path) if not isfile(join(yes_path, f))]\n",
    "print(yes_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([\"car\", \"cat\", \"dog\"])\n",
    "le.classes_\n",
    "le.transform([\"dog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit_transform([\"car\", \"cat\", \"dog\"])\n",
    "lb.transform([\"car\"])[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
